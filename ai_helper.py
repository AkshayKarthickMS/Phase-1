import streamlit as st
import google.generativeai as genai
import json

def get_gemini_analysis(fig, title, api_key):
    """
    Sends the Plotly figure's data to the Gemini API for a narrative explanation.

    Args:
        fig: The Plotly figure object.
        title: The title of the chart.
        api_key: The Google Gemini API key.

    Returns:
        A string containing the narrative explanation from the LLM, or None if an error occurs.
    """
    # Check if the API key is provided
    if not api_key:
        st.warning("Please enter your Google Gemini API Key in the sidebar to use this feature.")
        return None

    try:
        # Configure the Gemini API with the provided key
        genai.configure(api_key=api_key)
        
        # Use the requested Gemini 2.5 Flash model.
        # Note: Model names can change. If 'gemini-2.5-flash-latest' is not available,
        # try 'gemini-pro' or 'gemini-1.5-pro-latest'.
        model = genai.GenerativeModel('gemini-2.5-flash')

        # Convert the Plotly figure to JSON. This includes all data and layout information.
        # This is more accurate and token-efficient than sending an image of the chart.
        fig_json = fig.to_json()
        
        # Construct the prompt for the LLM
        prompt = f"""
        You are an expert public health data analyst. I will provide you with the JSON representation of a Plotly chart.
        Your task is to provide a concise, narrative explanation of the key insights, trends, and patterns visible in the chart.
        The title of the chart is: "{title}".
        
        Here is the chart data in JSON format:
        ```json
        {fig_json}
        ```
        
        Please provide your analysis below. Focus on the most important takeaways for a public health audience.
        """
        
        # Display a loading spinner while waiting for the API response
        with st.spinner(f"Generating analysis for '{title}' with Gemini..."):
            # Call the API to generate content
            response = model.generate_content(prompt)
            # Return the text generated by the model
            return response.text

    except Exception as e:
        # Handle any errors that occur during the API call
        st.error(f"An error occurred while calling the Gemini API: {e}")
        return None
